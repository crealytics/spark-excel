{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6173a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "# Please change to your path!!!\n",
    "ROOT=\"/home/quanghgx/spark-excel\"\n",
    "\n",
    "# Assembly or download spark-excel and its dependencies\n",
    "jars = [\n",
    "    \"/home/quanghgx/spark-excel/target/scala-2.12/spark-excel_2.12-0.13.7+63-744368f8-SNAPSHOT.jar\",\n",
    "    \"/home/quanghgx/jars/poi-ooxml-schemas-4.1.2.jar\",\n",
    "    \"/home/quanghgx/jars/commons-collections4-4.4.jar\",\n",
    "    \"/home/quanghgx/jars/xmlbeans-3.1.0.jar\"\n",
    "]\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.jars\", \",\".join(jars)) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd7a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"excel\") \\\n",
    "   .option(\"header\", True) \\\n",
    "   .option(\"inferSchema\", True) \\\n",
    "   .load(f\"{ROOT}/src/test/resources/spreadsheets/ca_dataset/2019/*/*.xlsx\") \\\n",
    "   .withColumn(\"file_name\", input_file_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d742504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+-----------------+----------------+--------------+--------------+--------------+--------------+--------------------+\n",
      "|Day|Month|Customer ID|    Customer Name|Standard Package|Extra Option 1|Extra Option 2|Extra Option 3|         Staff|           file_name|\n",
      "+---+-----+-----------+-----------------+----------------+--------------+--------------+--------------+--------------+--------------------+\n",
      "|  1|   11|      CA767|   Vũ Phương Thảo|           14000|          null|          null|          null|   Teresa Teng|file:///home/quan...|\n",
      "|  2|   11|      CA768|      Lê Thị Trâm|            null|          null|          2000|          null|Marilyn Monroe|file:///home/quan...|\n",
      "|  2|   11|      CA769|         Lê Trung|            null|          null|          1200|          null|   Teresa Teng|file:///home/quan...|\n",
      "|  3|   11|      CA770| Nguyễn Thảo Hiền|            null|          null|          1700|          null|   Teresa Teng|file:///home/quan...|\n",
      "|  3|   11|      CA771|   Nguyễn Thu Huệ|            null|          null|          1800|          null|   Teresa Teng|file:///home/quan...|\n",
      "|  3|   11|      CA772|      Vũ Cẩm Linh|            null|          null|           200|          null|   Teresa Teng|file:///home/quan...|\n",
      "|  3|   11|      CA773|    Phạm Kim Ngân|           12000|          null|          2000|          null|Marilyn Monroe|file:///home/quan...|\n",
      "|  4|   11|      CA774|Hoàng Thj Mai Anh|            5000|          null|          null|          null|Marilyn Monroe|file:///home/quan...|\n",
      "|  4|   11|      CA775|   Đỗ Phương Anh |            null|          null|           800|          null|Marilyn Monroe|file:///home/quan...|\n",
      "|  5|   11|      CA776|      Ngô Mai Quý|            null|          null|          1500|          null|   Teresa Teng|file:///home/quan...|\n",
      "+---+-----+-----------+-----------------+----------------+--------------+--------------+--------------+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e54e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+----------------+----------------+--------------+--------------+--------------+--------------+---------+\n",
      "|Day|Month|Customer ID|   Customer Name|Standard Package|Extra Option 1|Extra Option 2|Extra Option 3|         Staff|file_name|\n",
      "+---+-----+-----------+----------------+----------------+--------------+--------------+--------------+--------------+---------+\n",
      "|  1|   11|      CA767|  Vũ Phương Thảo|           14000|          null|          null|          null|   Teresa Teng|    ca_11|\n",
      "|  2|   11|      CA768|     Lê Thị Trâm|            null|          null|          2000|          null|Marilyn Monroe|    ca_11|\n",
      "|  2|   11|      CA769|        Lê Trung|            null|          null|          1200|          null|   Teresa Teng|    ca_11|\n",
      "|  3|   11|      CA770|Nguyễn Thảo Hiền|            null|          null|          1700|          null|   Teresa Teng|    ca_11|\n",
      "|  3|   11|      CA771|  Nguyễn Thu Huệ|            null|          null|          1800|          null|   Teresa Teng|    ca_11|\n",
      "+---+-----+-----------+----------------+----------------+--------------+--------------+--------------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "df.withColumn(\"file_name\", regexp_extract('file_name', '.*/(.*)\\.xlsx$', 1)) \\\n",
    "   .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2d4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"excel\") \\\n",
    "   .option(\"header\", True) \\\n",
    "   .option(\"inferSchema\", True) \\\n",
    "   .load(f\"{ROOT}/src/test/resources/spreadsheets/ca_dataset/2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2519e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Name: string (nullable = true)\n",
      " |-- Standard Package: integer (nullable = true)\n",
      " |-- Extra Option 1: integer (nullable = true)\n",
      " |-- Extra Option 2: integer (nullable = true)\n",
      " |-- Extra Option 3: integer (nullable = true)\n",
      " |-- Staff: string (nullable = true)\n",
      " |-- Quarter: integer (nullable = true)\n",
      "\n",
      "+-------+-----+\n",
      "|Quarter|count|\n",
      "+-------+-----+\n",
      "|      1|    7|\n",
      "|      3|  186|\n",
      "|      4|  224|\n",
      "|      2|  161|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.groupBy(\"Quarter\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458ef7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----+----+\n",
      "|RowID|        1|   2|   3|\n",
      "+-----+---------+----+----+\n",
      "|    0|File info|null|null|\n",
      "|    1|     Info|Info|Info|\n",
      "|    3| Metadata|null|null|\n",
      "|    5|     null|   1|   2|\n",
      "|    6|        A|   1|   2|\n",
      "|    7|        B|   5|   6|\n",
      "|    8|        C|   9|  10|\n",
      "|   11| Metadata|null|null|\n",
      "|   13|     null|   1|   2|\n",
      "|   14|        A|   1|   2|\n",
      "|   15|        B|   4|   5|\n",
      "|   16|        C|   7|   8|\n",
      "+-----+---------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"RowID\", IntegerType(), True),\n",
    "    StructField(\"1\", StringType(), True),\n",
    "    StructField(\"2\", StringType(), True),\n",
    "    StructField(\"3\", StringType(), True)  \n",
    "])\n",
    "df = spark.read.format(\"excel\") \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", False) \\\n",
    "    .option(\"columnNameOfRowNumber\", \"RowID\") \\\n",
    "    .load(f\"{ROOT}/src/test/resources/spreadsheets/issue_285_bryce21.xlsx\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8eb322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----+----+\n",
      "|RowID|        1|   2|   3|\n",
      "+-----+---------+----+----+\n",
      "|    0|File info|null|null|\n",
      "|    1|     Info|Info|Info|\n",
      "| null|     null|null|null|\n",
      "|    3| Metadata|null|null|\n",
      "| null|     null|null|null|\n",
      "|    5|     null|   1|   2|\n",
      "|    6|        A|   1|   2|\n",
      "|    7|        B|   5|   6|\n",
      "|    8|        C|   9|  10|\n",
      "| null|     null|null|null|\n",
      "| null|     null|null|null|\n",
      "|   11| Metadata|null|null|\n",
      "| null|     null|null|null|\n",
      "|   13|     null|   1|   2|\n",
      "|   14|        A|   1|   2|\n",
      "|   15|        B|   4|   5|\n",
      "|   16|        C|   7|   8|\n",
      "+-----+---------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"excel\") \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", False) \\\n",
    "    .option(\"keepUndefinedRows\", True) \\\n",
    "    .option(\"columnNameOfRowNumber\", \"RowID\") \\\n",
    "    .load(f\"{ROOT}/src/test/resources/spreadsheets/issue_285_bryce21.xlsx\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab7e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
